{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextMining_RNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOCwGd6wzWFy5RgsgWHzcT/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HBxVGtx0xGX_"},"source":["# Model trainer"]},{"cell_type":"markdown","metadata":{"id":"GrhgB3FnxCwe"},"source":["## Hardware setup"]},{"cell_type":"code","metadata":{"id":"rAOxU1-8w1ZW","executionInfo":{"status":"ok","timestamp":1607357595560,"user_tz":-60,"elapsed":4033,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}}},"source":["import torch\n","from torch import nn, cuda\n","import pandas as pd\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rRhlgmixB1n","executionInfo":{"status":"ok","timestamp":1607357595563,"user_tz":-60,"elapsed":4025,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"b0aeace1-356d-47bd-c678-aca928f64f21"},"source":["ngpu = torch.cuda.device_count()\n","# number of GPU units\n","print(\"Devices:\", ngpu)\n","for i in range(ngpu):\n","  print(\"- \", torch.cuda.get_device_name(i))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Devices: 1\n","-  Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RKB0hnMlxLmG"},"source":["## Model example"]},{"cell_type":"markdown","metadata":{"id":"3tnGhlX4jye6"},"source":["https://lirnli.wordpress.com/2017/09/01/simple-pytorch-rnn-examples/\n","\n","https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"waUgyuTNxLEw","executionInfo":{"status":"ok","timestamp":1607357595931,"user_tz":-60,"elapsed":4382,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"a38d281c-2ce7-4178-9b16-185376a3187e"},"source":["# input tensor\n","# each item ~ N(0,1)\n","input = torch.randn(5, 3, 10) # shape\n","\n","print(input.shape)\n","print(input[0,0,:]) # input vector within one batch"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3, 10])\n","tensor([-1.6374, -0.4167, -1.1926,  0.7392, -0.0980,  0.8811,  0.2278, -0.6878,\n","        -0.5954,  1.2310])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZF-sEk_xRTV","executionInfo":{"status":"ok","timestamp":1607357595932,"user_tz":-60,"elapsed":4373,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"240f55fe-cb44-420f-8241-244d5b554c58"},"source":["# initial state\n","h0 = torch.randn(2,  # number of layers * number of directions\n","                 3,  # batch\n","                 20) # hidden state\n","\n","print(h0.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3, 20])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8-ecShdxTeW","executionInfo":{"status":"ok","timestamp":1607357595934,"user_tz":-60,"elapsed":4364,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"c8d20366-b9e8-438a-ef67-5696a0390b4e"},"source":["# create architecture\n","rnn = torch.nn.RNN(10, # input size\n","                   20, # hidden size\n","                   2)  # number of layers\n","# train\n","output, hn = rnn(input, # input of shape (seq_len, batch, input_size)\n","                 h0)    # initial hidden state (num_layers * num_directions, batch, hidden_size)\n","\n","print(output.shape)\n","print(hn.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3, 20])\n","torch.Size([2, 3, 20])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fmnAYjCgx_Y1"},"source":["## Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4NGEX7AyAUW","executionInfo":{"status":"ok","timestamp":1607357617003,"user_tz":-60,"elapsed":25423,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"50d3c3cf-3666-4cd0-b43b-e967c17199d3"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/drive', force_remount=True)\n","\n","# read csv from drive\n","words = pd.read_csv('/drive/My Drive/Colab Notebooks/data/words.csv')\n","# parse text column\n","words['text'] = words.text.apply(eval)\n","\n","print(\"Loaded data: %d rows\" % (words.shape[0]))\n","print(\"Attributes:\", words.columns.to_list())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n","Loaded data: 196292 rows\n","Attributes: ['text', 'label', 'source']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tB0MLwL0VXtQ"},"source":["## Train / Load model"]},{"cell_type":"markdown","metadata":{"id":"AVO8ctKSjP9H"},"source":["https://datamahadev.com/word2vec-implementation-using-python-gensim-and-google-colab/\n","\n","https://blog.usejournal.com/train-your-first-gan-model-from-scratch-using-pytorch-9b72987fd2c0\n","\n","https://streamhacker.com/2014/12/29/word2vec-nltk/"]},{"cell_type":"code","metadata":{"id":"Y2YMr9OpzIss","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607357626947,"user_tz":-60,"elapsed":35353,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"bf3e2cd6-4b74-4d86-87d3-a4a8c16aa7a8"},"source":["retrain = False\n","\n","from gensim.models import Word2Vec\n","model_path = '/drive/My Drive/Colab Notebooks/models/word2vec.model'\n","\n","if retrain: # train and save\n","  # train model\n","  word2vec = Word2Vec(words.text, min_count = 1, size = 100, workers = 4)\n","\n","  # save model\n","  word2vec.save(model_path)\n","\n","else: # load\n","  word2vec = Word2Vec.load(model_path)\n","\n","# print model\n","print(word2vec)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=307967, size=100, alpha=0.025)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2c16EMYEVa13"},"source":["## Vectorize texts"]},{"cell_type":"markdown","metadata":{"id":"zy_YxJk16ROj"},"source":["Can be later integrated into the model as initial embedding layer."]},{"cell_type":"markdown","metadata":{"id":"3aYkVKWQjFZq"},"source":["https://intellipaat.com/community/12732/using-pre-trained-word2vec-with-lstm-for-word-generation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"qh5yNBH1ykSA","executionInfo":{"status":"ok","timestamp":1607357626949,"user_tz":-60,"elapsed":35340,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"6e544682-e6ca-49ff-e3be-b6283f676995"},"source":["# length of each sentences\n","K = words.text.apply(len)\n","\n","# plot ratio\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (12,12)\n","pd.Series(K).plot(kind = \"hist\", bins = 35);\n","\n","# maximum sentence length\n","Kmax = K.max()\n","print(\"Maximal sentence length:\", Kmax)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Maximal sentence length: 2832\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAuYAAAKrCAYAAAC9X0jhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7Dld33f99fbWoPBMUhYG4VKcle2NXZk4sRiDeq4cR0rFgskFmltIiYxG6qidBCN3aZjC+qJPGBmRNuYoI7NREYqEnEsE2wHpYjIG0zi6UwEWn4YEJhoI4S1MqANkpFjbKjwu3/c7zony93VlbT33vfufTxmztzv+Xy/55zPme+cq+d+9T3fW90dAABge33ddk8AAAAQ5gAAMIIwBwCAAYQ5AAAMIMwBAGCAXds9gSnOPvvs3rNnz3ZPAwCA09wHP/jB/9Ddu48dF+aLPXv25ODBg9s9DQAATnNV9Zn1xp3KAgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAXZt9wR2uj3XvPukPM991734pDwPAADbwxFzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAJsW5lV1U1U9WFUfX2fd36+qrqqzl/tVVddX1aGq+mhVXbyy7f6qume57V8Zf25VfWx5zPVVVcv4s6rqwLL9gao6a7PeIwAAnCybecT8bUn2HTtYVecnuSzJ764MvzDJhcvtqiRvWbZ9VpJrkzw/yfOSXLsS2m9J8sqVxx19rWuSvLe7L0zy3uU+AACMtmlh3t2/leShdVa9KclPJumVscuT3NJr7kxyZlU9O8kLkhzo7oe6++EkB5LsW9Y9o7vv7O5OckuSl6w8183L8s0r4wAAMNaWnmNeVZcneaC7f/uYVecmuX/l/uFl7ETjh9cZT5Jzuvuzy/LnkpxzgvlcVVUHq+rgkSNHHu/bAQCAk2bLwryqnp7ktUn+wVa95nI0vU+w/obu3tvde3fv3r1V0wIAgK+xlUfMvy3JBUl+u6ruS3Jekg9V1Z9L8kCS81e2PW8ZO9H4eeuMJ8nnl1Ndsvx88KS/EwAAOMm2LMy7+2Pd/We7e09378na6ScXd/fnktyW5OXL1VkuSfLF5XSUO5JcVlVnLV/6vCzJHcu6R6rqkuVqLC9P8q7lpW5LcvTqLftXxgEAYKzNvFziLyf5t0m+o6oOV9WVJ9j89iT3JjmU5BeTvCpJuvuhJK9Pctdye90ylmWbty6P+fdJ3rOMX5fkh6rqniR/dbkPAACj7dqsJ+7ulz3G+j0ry53k6uNsd1OSm9YZP5jkOeuMfyHJpY9zugAAsK385U8AABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwACbFuZVdVNVPVhVH18Z+z+q6neq6qNV9etVdebKutdU1aGq+lRVvWBlfN8ydqiqrlkZv6Cq3r+M/0pVPWUZf+py/9Cyfs9mvUcAADhZNvOI+duS7Dtm7ECS53T3dyf5d0lekyRVdVGSK5J81/KYX6iqM6rqjCQ/n+SFSS5K8rJl2yR5Y5I3dfe3J3k4yZXL+JVJHl7G37RsBwAAo21amHf3byV56Jix3+juR5e7dyY5b1m+PMmt3f3l7v50kkNJnrfcDnX3vd39lSS3Jrm8qirJDyZ55/L4m5O8ZOW5bl6W35nk0mV7AAAYazvPMf/vk7xnWT43yf0r6w4vY8cb/+Ykv78S+UfH/7PnWtZ/cdn+a1TVVVV1sKoOHjly5Em/IQAAeKK2Jcyr6n9L8miSX9qO1z+qu2/o7r3dvXf37t3bORUAAHa4XVv9glX1d5L8tSSXdncvww8kOX9ls/OWsRxn/AtJzqyqXctR8dXtjz7X4araleSZy/YAADDWlh4xr6p9SX4yyQ9395dWVt2W5IrliioXJLkwyQeS3JXkwuUKLE/J2hdEb1uC/n1JfmR5/P4k71p5rv3L8o8k+c2VfwAAAMBIm3bEvKp+OckPJDm7qg4nuTZrV2F5apIDy/cx7+zu/7G7766qdyT5RNZOcbm6u7+6PM+rk9yR5IwkN3X33ctL/FSSW6vqZ5N8OMmNy/iNSd5eVYey9uXTKzbrPQIAwMmyaWHe3S9bZ/jGdcaObv+GJG9YZ/z2JLevM35v1q7acuz4Hyf50cc1WQAA2Gb+8icAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYIBNC/OquqmqHqyqj6+MPauqDlTVPcvPs5bxqqrrq+pQVX20qi5eecz+Zft7qmr/yvhzq+pjy2Our6o60WsAAMBkm3nE/G1J9h0zdk2S93b3hUneu9xPkhcmuXC5XZXkLclaZCe5NsnzkzwvybUrof2WJK9cedy+x3gNAAAYa9PCvLt/K8lDxwxfnuTmZfnmJC9ZGb+l19yZ5MyqenaSFyQ50N0PdffDSQ4k2bese0Z339ndneSWY55rvdcAAICxtvoc83O6+7PL8ueSnLMsn5vk/pXtDi9jJxo/vM74iV4DAADG2rYvfy5Huns7X6Oqrqqqg1V18MiRI5s5FQAAOKGtDvPPL6ehZPn54DL+QJLzV7Y7bxk70fh564yf6DW+Rnff0N17u3vv7t27n/CbAgCAJ2urw/y2JEevrLI/ybtWxl++XJ3lkiRfXE5HuSPJZVV11vKlz8uS3LGse6SqLlmuxvLyY55rvdcAAICxdm3WE1fVLyf5gSRnV9XhrF1d5bok76iqK5N8JslLl81vT/KiJIeSfCnJK5Kkux+qqtcnuWvZ7nXdffQLpa/K2pVfnpbkPcstJ3gNAAAYa9PCvLtfdpxVl66zbSe5+jjPc1OSm9YZP5jkOeuMf2G91wAAgMn85U8AABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAATYU5lX1FzZ7IgAAsJNt9Ij5L1TVB6rqVVX1zE2dEQAA7EAbCvPu/stJ/laS85N8sKr+aVX90KbODAAAdpANn2Pe3fck+ekkP5Xkv0lyfVX9TlX9t5s1OQAA2Ck2eo75d1fVm5J8MskPJvnr3f3nl+U3beL8AABgR9i1we3+ryRvTfLa7v6jo4Pd/XtV9dObMjMAANhBNhrmL07yR9391SSpqq9L8g3d/aXufvumzQ4AAHaIjZ5j/q+SPG3l/tOXMQAA4CTYaJh/Q3f/x6N3luWnb86UAABg59lomP9hVV189E5VPTfJH51gewAA4HHY6DnmP5Hkn1XV7yWpJH8uyd/ctFkBAMAOs6Ew7+67quo7k3zHMvSp7v7/Nm9aAACws2z0iHmSfG+SPctjLq6qdPctmzIrAADYYTYU5lX19iTfluQjSb66DHcSYQ4AACfBRo+Y701yUXf3yXjRqvqfk/wPWYv7jyV5RZJnJ7k1yTcn+WCSH+vur1TVU7P2D4DnJvlCkr/Z3fctz/OaJFdm7R8Lf6+771jG9yV5c5Izkry1u687GfMGAIDNstGrsnw8a1/4fNKq6twkfy/J3u5+Ttbi+Yokb0zypu7+9iQPZy24s/x8eBl/07Jdquqi5XHflWRfkl+oqjOq6owkP5/khUkuSvKyZVsAABhro2F+dpJPVNUdVXXb0duTeN1dSZ5WVbuydj30zyb5wSTvXNbfnOQly/Lly/0s6y+tqlrGb+3uL3f3p5McSvK85Xaou+/t7q9k7Sj85U9irgAAsOk2eirLz5ysF+zuB6rq/0zyu1m7FvpvZO3Uld/v7keXzQ4nOXdZPjfJ/ctjH62qL2btdJdzk9y58tSrj7n/mPHnrzeXqroqyVVJ8i3f8i1P7o0BAMCTsKEj5t39b5Lcl+Trl+W7knzoibxgVZ2VtSPYFyT5L5J8Y9ZORdly3X1Dd+/t7r27d+/ejikAAECSDYZ5Vb0ya6eR/ONl6Nwk//wJvuZfTfLp7j6yXAv915J8X5Izl1NbkuS8JA8syw8kOX+Zx64kz8zal0D/dPyYxxxvHAAAxtroOeZXZy2eH0mS7r4nyZ99gq/5u0kuqaqnL+eKX5rkE0nel+RHlm32J3nXsnzbcj/L+t9crg5zW5IrquqpVXVBkguTfCBrR/MvrKoLquopWfuC6JM5Hx4AADbdRs8x//Jy6cIkf3rk+gldOrG7319V78zaqTCPJvlwkhuSvDvJrVX1s8vYjctDbkzy9qo6lOShrIV2uvvuqnpH1qL+0SRXd/dXl/m9OskdWbviy03dffcTmSsAAGyVjYb5v6mq12btSio/lORVSf7FE33R7r42ybXHDN+btSuqHLvtHyf50eM8zxuSvGGd8duT3P5E5wcAAFtto6eyXJPkSNb+GNDfzVr0/vRmTQoAAHaaDR0x7+4/SfKLyw0AADjJNhTmVfXprHNOeXd/60mfEQAA7EAbPcd878ryN2TtnO9nnfzpAADAzrTRPzD0hZXbA939j5K8eJPnBgAAO8ZGT2W5eOXu12XtCPpGj7YDAACPYaNx/Q9Xlh9Ncl+Sl5702QAAwA610auy/JXNnggAAOxkGz2V5X850fru/rmTMx0AANiZHs9VWb43yW3L/b+e5ANJ7tmMSQEAwE6z0TA/L8nF3f0HSVJVP5Pk3d39tzdrYgAAsJNs6HKJSc5J8pWV+19ZxgAAgJNgo0fMb0nygar69eX+S5LcvDlTAgCAnWejV2V5Q1W9J8lfXoZe0d0f3rxpAQDAzrLRU1mS5OlJHunuNyc5XFUXbNKcAABgx9lQmFfVtUl+KslrlqGvT/JPNmtSAACw02z0iPnfSPLDSf4wSbr795J802ZNCgAAdpqNhvlXuruTdJJU1Tdu3pQAAGDn2WiYv6Oq/nGSM6vqlUn+VZJf3LxpAQDAzvKYV2WpqkryK0m+M8kjSb4jyT/o7gObPDcAANgxHjPMu7ur6vbu/gtJxDgAAGyCjZ7K8qGq+t5NnQkAAOxgG/3Ln89P8rer6r6sXZmlsnYw/bs3a2IAALCTnDDMq+pbuvt3k7xgi+YDAAA70mMdMf/nSS7u7s9U1a9293+3FZMCAICd5rHOMa+V5W/dzIkAAMBO9lhh3sdZBgAATqLHOpXlL1bVI1k7cv60ZTn5T1/+fMamzg4AAHaIE4Z5d5+xVRMBAICdbKPXMQcAADaRMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAANsS5hX1ZlV9c6q+p2q+mRV/VdV9ayqOlBV9yw/z1q2raq6vqoOVdVHq+rilefZv2x/T1XtXxl/blV9bHnM9VVV2/E+AQBgo7briPmbk/zL7v7OJH8xySeTXJPkvd19YZL3LveT5IVJLlxuVyV5S5JU1bOSXJvk+Umel+TaozG/bPPKlcft24L3BAAAT9iWh3lVPTPJ9ye5MUm6+yvd/ftJLk9y87LZzUlesixfnuSWXnNnkjOr6tlJXpDkQHc/1N0PJzmQZN+y7hndfWd3d5JbVp4LAABG2o4j5hckOZLk/66qD1fVW6vqG5Oc092fXbb5XJJzluVzk9y/8vjDy9iJxg+vM/41quqqqjpYVQePHDnyJN8WAAA8cdsR5ruSXJzkLd39PUn+MP/ptJUkyXKkuzd7It19Q3fv7e69u3fv3uyXAwCA49qOMD+c5HB3v3+5/86shfrnl9NQsvx8cFn/QJLzVx5/3jJ2ovHz1hkHAICxtjzMu/tzSe6vqu9Yhi5N8okktyU5emWV/UnetSzfluTly9VZLknyxeWUlzuSXFZVZy1f+rwsyR3Lukeq6pLlaiwvX3kuAAAYadc2ve7/lOSXquopSe5N8oqs/SPhHVV1ZZLPJHnpsu3tSV6U5FCSLy3bprsfqqrXJ7lr2e513f3QsvyqJG9L8rQk71luAAAw1raEeXd/JMnedVZdus62neTq4zzPTUluWmf8YJLnPMlpAgDAlvGXPwEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAA2xbmFfVGVX14ar6f5b7F1TV+6vqUFX9SlU9ZRl/6nL/0LJ+z8pzvGYZ/1RVvWBlfN8ydqiqrtnq9wYAAI/Xdh4x//Ekn1y5/8Ykb+rub0/ycJIrl/Erkzy8jL9p2S5VdVGSK5J8V5J9SX5hif0zkvx8khcmuSjJy5ZtAQBgrG0J86o6L8mLk7x1uV9JfjDJO5dNbk7ykmX58uV+lvWXLttfnuTW7v5yd386yaEkz1tuh7r73u7+SpJbl20BAGCs7Tpi/o+S/GSSP1nuf3OS3+/uR5f7h5Ocuyyfm+T+JFnWf3HZ/k/Hj3nM8ca/RlVdVVUHq+rgkSNHnux7AgCAJ2zLw7yq/lqSB7v7g1v92sfq7hu6e2937929e/d2TwcAgB1s1za85vcl+eGqelGSb0jyjCRvTnJmVe1ajoqfl+SBZfsHkpyf5HBV7UryzCRfWBk/avUxxxsHAICRtvyIeXe/prvP6+49Wfvy5m92999K8r4kP7Jstj/Ju5bl25b7Wdb/Znf3Mn7FctWWC5JcmOQDSe5KcuFylZenLK9x2xa8NQAAeMK244j58fxUklur6meTfDjJjcv4jUneXlWHkjyUtdBOd99dVe9I8okkjya5uru/miRV9eokdyQ5I8lN3X33lr4TAAB4nLY1zLv7Xyf518vyvVm7osqx2/xxkh89zuPfkOQN64zfnuT2kzhVAADYVP7yJwAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGGDXdk+Ak2PPNe9+0s9x33UvPgkzAQDgiXDEHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYIAtD/OqOr+q3ldVn6iqu6vqx5fxZ1XVgaq6Z/l51jJeVXV9VR2qqo9W1cUrz7V/2f6eqtq/Mv7cqvrY8pjrq6q2+n0CAMDjsR1HzB9N8ve7+6IklyS5uqouSnJNkvd294VJ3rvcT5IXJrlwuV2V5C3JWsgnuTbJ85M8L8m1R2N+2eaVK4/btwXvCwAAnrAtD/Pu/mx3f2hZ/oMkn0xybpLLk9y8bHZzkpcsy5cnuaXX3JnkzKp6dpIXJDnQ3Q9198NJDiTZt6x7Rnff2d2d5JaV5wIAgJG29RzzqtqT5HuSvD/JOd392WXV55Kcsyyfm+T+lYcdXsZONH54nXEAABhr28K8qv5Mkl9N8hPd/cjquuVId2/BHK6qqoNVdfDIkSOb/XIAAHBc2xLmVfX1WYvyX+ruX1uGP7+chpLl54PL+ANJzl95+HnL2InGz1tn/Gt09w3dvbe79+7evfvJvSkAAHgStuOqLJXkxiSf7O6fW1l1W5KjV1bZn+RdK+MvX67OckmSLy6nvNyR5LKqOmv50udlSe5Y1j1SVZcsr/XylecCAICRdm3Da35fkh9L8rGq+sgy9tok1yV5R1VdmeQzSV66rLs9yYuSHErypSSvSJLufqiqXp/krmW713X3Q8vyq5K8LcnTkrxnuQEAwFhbHubd/f8mOd51xS9dZ/tOcvVxnuumJDetM34wyXOexDQBAGBL+cufAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwADCHAAABhDmAAAwgDAHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAALu2ewLMseead5+U57nvuheflOcBANhJHDEHAIABhDkAAAwgzAEAYABhDgAAAwhzAAAYQJgDAMAAwhwAAAYQ5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAGEOYAADCAMAcAgAGEOQAADCDMAQBgAGEOAAADCHMAABhAmAMAwAC7tnsCnH72XPPuJ/0c91334pMwEwCAU4cj5gAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAMIcAAAG8AeGGMkfKQIAdhpHzAEAYABhDgAAAziVhdPWyTgdJnFKDACwNU7bMK+qfUnenOSMJG/t7uu2eUqcok5W4E/hHxoAMNNpGeZVdUaSn0/yQ0kOJ7mrqm7r7k9s78xg+/liLQDMdFqGeZLnJdYIaTQAAATUSURBVDnU3fcmSVXdmuTyJMIcTgL/FwEATr7TNczPTXL/yv3DSZ5/7EZVdVWSq5a7/7GqPrUFczvW2Un+wza8Lk+M/XXq2PC+qjdu8kzYCJ+tU4d9dWqxv2b6L9cbPF3DfEO6+4YkN2znHKrqYHfv3c45sHH216nDvjq12F+nDvvq1GJ/nVpO18slPpDk/JX75y1jAAAw0uka5nclubCqLqiqpyS5Islt2zwnAAA4rtPyVJbufrSqXp3kjqxdLvGm7r57m6d1PNt6Kg2Pm/116rCvTi3216nDvjq12F+nkOru7Z4DAADseKfrqSwAAHBKEeYAADCAMN9GVbWvqj5VVYeq6prtng9JVd1XVR+rqo9U1cFl7FlVdaCq7ll+nrWMV1Vdv+y/j1bVxds7+9NfVd1UVQ9W1cdXxh73/qmq/cv291TV/u14L6e74+yrn6mqB5bP10eq6kUr616z7KtPVdULVsb9ntxkVXV+Vb2vqj5RVXdX1Y8v4z5bA51gf/l8nQ66220bbln7Uuq/T/KtSZ6S5LeTXLTd89rptyT3JTn7mLH/Pck1y/I1Sd64LL8oyXuSVJJLkrx/u+d/ut+SfH+Si5N8/InunyTPSnLv8vOsZfms7X5vp9vtOPvqZ5L8r+tse9HyO/CpSS5Yfjee4ffklu2rZye5eFn+piT/btknPlsDbyfYXz5fp8HNEfPt87wkh7r73u7+SpJbk1y+zXNifZcnuXlZvjnJS1bGb+k1dyY5s6qevR0T3Cm6+7eSPHTM8OPdPy9IcqC7H+ruh5McSLJv82e/sxxnXx3P5Ulu7e4vd/enkxzK2u9Ivye3QHd/trs/tCz/QZJPZu0vaPtsDXSC/XU8Pl+nEGG+fc5Ncv/K/cM58QeLrdFJfqOqPlhVVy1j53T3Z5flzyU5Z1m2D2d4vPvHftter15Of7jp6KkRsa/GqKo9Sb4nyfvjszXeMfsr8fk65Qlz+M/91919cZIXJrm6qr5/dWV3d9binYHsn/HekuTbkvylJJ9N8g+3dzqsqqo/k+RXk/xEdz+yus5na5519pfP12lAmG+fB5Kcv3L/vGWMbdTdDyw/H0zy61n7X32fP3qKyvLzwWVz+3CGx7t/7Ldt0t2f7+6vdvefJPnFrH2+Evtq21XV12ct8n6pu39tGfbZGmq9/eXzdXoQ5tvnriQXVtUFVfWUJFckuW2b57SjVdU3VtU3HV1OclmSj2dtvxy9usD+JO9alm9L8vLlCgWXJPniyv/2Zes83v1zR5LLquqs5X/1XraMscmO+Q7G38ja5ytZ21dXVNVTq+qCJBcm+UD8ntwSVVVJbkzyye7+uZVVPlsDHW9/+XydHnZt9wR2qu5+tKpenbVfWmckuam7797mae105yT59bXfedmV5J9297+sqruSvKOqrkzymSQvXba/PWtXJziU5EtJXrH1U95ZquqXk/xAkrOr6nCSa5Ncl8exf7r7oap6fdb+o5Qkr+vujX5JkQ06zr76gar6S1k7JeK+JH83Sbr77qp6R5JPJHk0ydXd/dXlefye3Hzfl+THknysqj6yjL02PltTHW9/vczn69RXa6eNAQAA28mpLAAAMIAwBwCAAYQ5AAAMIMwBAGAAYQ4AAAMIcwAAGECYAwDAAP8/iRQrYdwcqO8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x864 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uTBcTyVs0YTm","executionInfo":{"status":"ok","timestamp":1607357627416,"user_tz":-60,"elapsed":35790,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"5271d6e4-b0c6-4feb-dd43-6efae9afaa1b"},"source":["# drop too long sentences\n","d1 = words.shape[0]\n","input_size = 1200\n","words = words[K <= input_size]\\\n","  .reset_index(drop = True)\n","d2 = words.shape[0]\n","\"Dropped %d of %d samples (%5.3f %%).\" % (d1 - d2, d1, (1 - d2/d1) * 100)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Dropped 305 of 196292 samples (0.155 %).'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"p4NdIegBabgx","executionInfo":{"status":"ok","timestamp":1607357627777,"user_tz":-60,"elapsed":36134,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"4813dd0d-67c0-403a-c297-8f0fcfeb591f"},"source":["# length of each sentences\n","K = words.text.apply(len)\n","\n","# plot ratio\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (12,12)\n","pd.Series(K).plot(kind = \"hist\", bins = 60);\n","\n","# maximum sentence length\n","Kmax = K.max()\n","print(\"Maximal sentence length:\", Kmax)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Maximal sentence length: 1200\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x864 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"maVuoliJODK0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607357651838,"user_tz":-60,"elapsed":60181,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}},"outputId":"63127b09-79dc-41db-c4ad-9558134ad89c"},"source":["# dimensions\n","N    = words.shape[0]\n","K    = words.text.apply(len).to_numpy()\n","Kmax = K.max()\n","\n","# train data\n","train_y = words.label.to_numpy()\n","train_x = np.zeros([N, Kmax], dtype=np.int32)\n","for i,row in words.iterrows():\n","  for j,word in enumerate(row.text):\n","    # map words\n","    train_x[i,j] = word2vec.wv.vocab[word].index\n","\n","# remove empty lines\n","nonempty_lines = K > 0\n","train_x = train_x[nonempty_lines,:]\n","train_y = train_y[nonempty_lines]\n","K = K[nonempty_lines]\n","\n","# result\n","print(\"Train data |%d x %d|\" % (train_x.shape))\n","print(\"Labels |%d x 1|\" % (train_y.shape))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Train data |195950 x 1200|\n","Labels |195950 x 1|\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Uj80Ygog73U"},"source":["## Model definition"]},{"cell_type":"markdown","metadata":{"id":"XDbCVQHai6Mj"},"source":["https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n","\n","https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n","\n","https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/402_RNN_classifier.py"]},{"cell_type":"markdown","metadata":{"id":"6CR5c2uig-Tb"},"source":["### Generator"]},{"cell_type":"code","metadata":{"id":"lFyyysharJNo","executionInfo":{"status":"ok","timestamp":1607357651840,"user_tz":-60,"elapsed":60173,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"}}},"source":["class Generator(nn.Module):\n","  \"\"\"Generator code.\"\"\"\n","  def __init__(self, output_size, input_size = 1, hidden_state = 5, num_layers = 1):\n","    \"\"\"Generator constructor.\n","    \n","    Args:\n","      ngpu (int): Number of GPUs.\n","      kfeat (int, optional): Number of features, by default 1.\n","    \"\"\"\n","    super(Generator, self).__init__()\n","    \n","    # LSTM layer\n","    self.lstm = nn.LSTM(input_size,   # input size\n","                        hidden_state, # hidden size\n","                        num_layers)   # number of layers\n","\n","    # linear final layer\n","    self.linear = nn.Linear(hidden_state, output_size)\n","\n","  def forward(self, input):\n","    h1, (hn, cn) = self.lstm(input)\n","    o  = self.linear(h1)\n","    return o\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-JbT7yy6h3a","outputId":"0f87b0e6-66d5-48dc-90f1-d12a63063eba"},"source":["hidden_size = 60\n","vocab_size = len(word2vec.wv.vocab)\n","batch_size = 10\n","num_layers = 2\n","num_epochs = 1\n","learning_rate = 0.02\n","\n","# connect to device\n","#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","# instantiate \n","model = Generator(vocab_size, 1, #input_size\n","                  hidden_size, num_layers)\\\n","  .to(device)\n","print(model)\n","\n","# loss, optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# inputs\n","train_x_torch = torch.from_numpy(train_x.astype(np.float32))\n","train_y_torch = torch.from_numpy(train_y.astype(np.float32))\n","\n","print(\"Input matrix:\", train_x.shape)\n","print(\"Input targets:\", train_y.shape)\n","\n","for epoch in range(num_epochs):\n","    # Set initial hidden and cell states\n","    #states = (torch.zeros(input_size, hidden_size).to(device),\n","    #          torch.zeros(hidden_size, hidden_size).to(device))\n","\n","    for i in range(0, train_x.shape[0], batch_size):\n","      # get input\n","      #input_vector = train_x_torch[i,:K[i]]#.view(1, 1, input_size)\n","      #input_target = train_y_torch[i]#.view(1, 1)#.reshape((-1,input_size))\n","      #train_x_input = train_x[i,:K[i]].astype(np.float32)\n","      #train_y_input = train_y[i].astype(np.float32)\n","      #print(\"Input vector:\", train_x_input.shape)\n","      #print(\"Input target:\", train_y_input.shape)\n","      batch_end = min(i + batch_size, train_x.shape[0])\n","      batch_size_ = batch_end - i\n","      input_vector = train_x_torch[i:batch_end,:K[i]]\\\n","        .reshape((batch_size_,K[i],1))#\\.to(device)\n","      input_target = train_y_torch[i:batch_end]\\\n","        .reshape((batch_size_))#\\.to(device)\n","      #print(\"Input vector:\", input_vector.shape)\n","      #print(\"Input target:\", input_target.shape)\n","      #break\n","      # truncated backpropagation\n","      #states = [state.detach() for state in states]\n","      #print(input_vector.shape)\n","      output = model(input_vector)\n","      #print(\"Output:\", output.shape)\n","\n","      # classical\n","      #loss = loss_fn(output, input_target) # \n","      #model.zero_grad()\n","      #loss.backward()\n","      # gradient clipping\n","        #torch.nn.utils.clip_grad_norm(model.parameters(), .5)\n","      #optimizer.step()\n","\n","      del input_vector\n","      del input_target\n","\n","      # add discriminator\n","    else:\n","      print ('Epoch [{}/{}], Loss: {:.4f}'\n","           .format(epoch+1, num_epochs, loss.item()))\n","      \n","    #for i in range(0, input_tensor.size(1) - timesteps, timesteps):\n","    #    # Get mini-batch inputs and targets\n","    #    inputs = input_tensor[:, i:i+timesteps].to(device)\n","    #    targets = input_tensor[:, (i+1):(i+1)+timesteps].to(device)\n","        \n","    #    states = detach(states)\n","    #    outputs,_ = model(inputs, states)\n","    #    loss = loss_fn(outputs, targets.reshape(-1))\n","\n","    #    model.zero_grad()\n","    #    loss.backward()\n","        # Perform Gradient Clipping\n","    #    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    #    optimizer.step()\n","    \n","    #else:\n","    #    print ('Epoch [{}/{}], Loss: {:.4f}'\n","    #       .format(epoch+1, num_epochs, loss.item()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generator(\n","  (lstm): LSTM(1, 60, num_layers=2)\n","  (linear): Linear(in_features=60, out_features=307967, bias=True)\n",")\n","Input matrix: (195950, 1200)\n","Input targets: (195950,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2JF_DUJBcXCW"},"source":["#def weights_init(m):\n","#  \"\"\"Custom weights initialization called on netG and netD.\"\"\"\n","#  classname = m.__class__.__name__\n","#  if classname.find('Conv') != -1:\n","#    nn.init.normal_(m.weight.data, 0.0, 0.02)\n","#  elif classname.find('BatchNorm') != -1:\n","#    nn.init.normal_(m.weight.data, 1.0, 0.02)\n","#    nn.init.constant_(m.bias.data, 0)\n","\n","#class Generator(nn.Module):\n","#  \"\"\"Generator code.\"\"\"\n","#  def __init__(self, ngpu):\n","#    super(Generator, self).__init__()\n","    \n","    # Number of GPUs available. Use 0 for CPU mode.\n","#    self.ngpu = ngpu\n","    # Batch size during training\n","#    self.batch_size = 128\n","    # Spatial size of training images. All images will be resized to this\n","    #   size using a transformer.\n","#    self.image_size = 64\n","    # Number of channels in the training images. For color images this is 3\n","#    self.nc = 3\n","    # Size of z latent vector (i.e. size of generator input)\n","#    self.nz = 100\n","    # Size of feature maps in generator\n","#    self.ngf = 64\n","    # Size of feature maps in discriminator\n","#    self.ndf = 64\n","    # Number of training epochs\n","#    self.num_epochs = 5\n","    # Beta1 hyperparam for Adam optimizers\n","#    self.beta1 = 0.5\n","\n","#    self.main = nn.Sequential(\n","      # input is Z, going into a convolution\n","#      nn.ConvTranspose2d( self.nz, self.ngf * 8, 4, 1, 0, bias=False),\n","#      nn.BatchNorm2d(self.ngf * 8),\n","#      nn.ReLU(True),\n","      # state size. (ngf*8) x 4 x 4\n","#      nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ngf * 4),\n","#      nn.ReLU(True),\n","      # state size. (ngf*4) x 8 x 8\n","#      nn.ConvTranspose2d( self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ngf * 2),\n","#      nn.ReLU(True),\n","      # state size. (ngf*2) x 16 x 16\n","#      nn.ConvTranspose2d( self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ngf),\n","#      nn.ReLU(True),\n","      # state size. (ngf) x 32 x 32\n","#      nn.ConvTranspose2d( self.ngf, self.nc, 4, 2, 1, bias=False),\n","#      nn.Tanh()\n","      # state size. (nc) x 64 x 64\n","#    )\n","\n","#  def forward(self, input):\n","#    return self.main(input)\n","\n","# Create the generator\n","#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","#print(\"Device used:\", device)\n","#netG = Generator(ngpu).to(device)\n","\n","# Handle multi-gpu if desired\n","#if (device.type == 'cuda') and (ngpu > 1):\n","#    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.2.\n","#netG.apply(weights_init)\n","\n","# Print the model\n","#print(netG)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mkG9I2pKhA5b"},"source":["### Discriminator"]},{"cell_type":"code","metadata":{"id":"pts3SkEaf6H7"},"source":["#class Discriminator(nn.Module):\n","#  def __init__(self, ngpu):\n","#    super(Discriminator, self).__init__()\n","    # Number of GPUs available. Use 0 for CPU mode.\n","#    self.ngpu = ngpu\n","    # Batch size during training\n","#    self.batch_size = 128\n","    # Spatial size of training images. All images will be resized to this\n","    #   size using a transformer.\n","#    self.image_size = 64\n","    # Number of channels in the training images. For color images this is 3\n","#    self.nc = 3\n","    # Size of z latent vector (i.e. size of generator input)\n","#   self.nz = 100\n","    # Size of feature maps in generator\n","#    self.ngf = 64\n","    # Size of feature maps in discriminator\n","#    self.ndf = 64\n","    # Number of training epochs\n","#    self.num_epochs = 5\n","    # Beta1 hyperparam for Adam optimizers\n","#    self.beta1 = 0.5\n","\n","#    self.main = nn.Sequential(\n","      # input is (nc) x 64 x 64\n","#      nn.Conv2d(self.nc, self.ndf, 4, 2, 1, bias=False),\n","#      nn.LeakyReLU(0.2, inplace=True),\n","      # state size. (ndf) x 32 x 32\n","#      nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ndf * 2),\n","#      nn.LeakyReLU(0.2, inplace=True),\n","      # state size. (ndf*2) x 16 x 16\n","#      nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ndf * 4),\n","#      nn.LeakyReLU(0.2, inplace=True),\n","      # state size. (ndf*4) x 8 x 8\n","#      nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False),\n","#      nn.BatchNorm2d(self.ndf * 8),\n","#      nn.LeakyReLU(0.2, inplace=True),\n","      # state size. (ndf*8) x 4 x 4\n","#      nn.Conv2d(self.ndf * 8, 1, 4, 1, 0, bias=False),\n","#      nn.Sigmoid()\n","#    )\n","\n","##  def forward(self, input):\n","#    return self.main(input)\n","\n","# Create the Discriminator\n","#netD = Discriminator(ngpu).to(device)\n","\n","# Handle multi-gpu if desired\n","#if (device.type == 'cuda') and (ngpu > 1):\n","#    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.2.\n","#netD.apply(weights_init)\n","\n","# Print the model\n","#print(netD)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tIPDRbXLhCnL"},"source":["### Optimizer\n"]},{"cell_type":"code","metadata":{"id":"VPepDlZ5gmEM"},"source":["# Initialize BCELoss function\n","#criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","#nz = 100\n","#fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","#real_label = 1.\n","#fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","#lr = 0.0002 # Learning rate for optimizers\n","#optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","#optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f5agAO7NhFir"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"ZVe6diUbhLuC"},"source":["# Training Loop\n","#num_epochs = 10\n","\n","# Lists to keep track of progress\n","#img_list = []\n","#G_losses = []\n","#D_losses = []\n","#iters = 0\n","\n","#print(\"Starting Training Loop...\")\n","# For each epoch\n","#for epoch in range(1,num_epochs+1):\n","    # For each batch in the dataloader\n","#    for i, data in enumerate(train_x, 1):\n","\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        #netD.zero_grad()\n","        # Format batch\n","        #real_cpu = data[0].to(device)\n","        #b_size = real_cpu.size(0)\n","        #label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","        # Forward pass real batch through D\n","        #output = netD(real_cpu).view(-1)\n","        # Calculate loss on all-real batch\n","        #errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        #errD_real.backward()\n","        #D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        #noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # Generate fake image batch with G\n","        #fake = netG(noise)\n","        #label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #output = netD(fake.detach()).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        #errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch\n","        #errD_fake.backward()\n","        #D_G_z1 = output.mean().item()\n","        # Add the gradients from the all-real and all-fake batches\n","        #errD = errD_real + errD_fake\n","        # Update D\n","        #optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        #netG.zero_grad()\n","        #label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        #output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        #errG = criterion(output, label)\n","        # Calculate gradients for G\n","        #errG.backward()\n","        #D_G_z2 = output.mean().item()\n","        # Update G\n","        #optimizerG.step()\n","\n","        # Output training stats\n","        #if i % 20000 == 0 or i == train_x.shape[0]:\n","        #    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","        #          % (epoch, num_epochs, i, train_x.shape[0],\n","        #             0, 0, 0, 0, 0))\n","                     #errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        #G_losses.append(errG.item())\n","        #D_losses.append(errD.item())\n","\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        #if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","        #    with torch.no_grad():\n","        #        fake = netG(fixed_noise).detach().cpu()\n","        #    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        #iters += 1"],"execution_count":null,"outputs":[]}]}