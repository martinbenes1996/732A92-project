{"cells":[{"metadata":{"id":"HBxVGtx0xGX_"},"cell_type":"markdown","source":"# Model trainer"},{"metadata":{"id":"GrhgB3FnxCwe"},"cell_type":"markdown","source":"## Hardware setup"},{"metadata":{"executionInfo":{"elapsed":4033,"status":"ok","timestamp":1607357595560,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"rAOxU1-8w1ZW","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn, cuda\nimport pandas as pd\nimport numpy as np","execution_count":1,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":4025,"status":"ok","timestamp":1607357595563,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"8rRhlgmixB1n","outputId":"b0aeace1-356d-47bd-c678-aca928f64f21","trusted":true},"cell_type":"code","source":"ngpu = torch.cuda.device_count()\n# number of GPU units\nprint(\"Devices:\", ngpu)\nfor i in range(ngpu):\n  print(\"- \", torch.cuda.get_device_name(i))","execution_count":2,"outputs":[{"output_type":"stream","text":"Devices: 0\n","name":"stdout"}]},{"metadata":{"id":"RKB0hnMlxLmG"},"cell_type":"markdown","source":"## Model example"},{"metadata":{"id":"3tnGhlX4jye6"},"cell_type":"markdown","source":"https://lirnli.wordpress.com/2017/09/01/simple-pytorch-rnn-examples/\n\nhttps://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677"},{"metadata":{"id":"fmnAYjCgx_Y1"},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"source = 'kaggle' # {'drive', 'kaggle'}\nretrain = False","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from drive\nif source == 'drive':\n    from google.colab import drive\n    drive.mount('/drive', force_remount=True)\n    path = '/drive/My Drive/Colab Notebooks/data/words.csv'\n    model_path = '/drive/My Drive/Colab Notebooks/models/word2vec.model'\n\n# from Kaggle\nelif source == 'kaggle':\n    path = '../input/732a92project/words.csv'\n    model_path = '../input/732a92project/word2vec.model'\n\n# nothing chosen\nelse: raise RuntimeError\n  ","execution_count":4,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":25423,"status":"ok","timestamp":1607357617003,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"c4NGEX7AyAUW","outputId":"50d3c3cf-3666-4cd0-b43b-e967c17199d3","trusted":true},"cell_type":"code","source":"# read csv from drive\nwords = pd.read_csv(path, engine='python')\n# parse text column\nwords['text'] = words.text.apply(eval)\n\nprint(\"Loaded data: %d rows\" % (words.shape[0]))\nprint(\"Attributes:\", words.columns.to_list())","execution_count":5,"outputs":[{"output_type":"stream","text":"Loaded data: 196292 rows\nAttributes: ['text', 'label', 'source']\n","name":"stdout"}]},{"metadata":{"id":"tB0MLwL0VXtQ"},"cell_type":"markdown","source":"## Train / Load model"},{"metadata":{"id":"AVO8ctKSjP9H"},"cell_type":"markdown","source":"https://datamahadev.com/word2vec-implementation-using-python-gensim-and-google-colab/\n\nhttps://blog.usejournal.com/train-your-first-gan-model-from-scratch-using-pytorch-9b72987fd2c0\n\nhttps://streamhacker.com/2014/12/29/word2vec-nltk/"},{"metadata":{"executionInfo":{"elapsed":35353,"status":"ok","timestamp":1607357626947,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"Y2YMr9OpzIss","outputId":"bf3e2cd6-4b74-4d86-87d3-a4a8c16aa7a8","trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\n\nif retrain: # train and save\n  # train model\n  word2vec = Word2Vec(words.text, min_count = 1, size = 100, workers = 4)\n\n  # save model\n  word2vec.save(model_path)\n\nelse: # load\n  word2vec = Word2Vec.load(model_path)\n\n# print model\nprint(word2vec)","execution_count":6,"outputs":[{"output_type":"stream","text":"Word2Vec(vocab=307967, size=100, alpha=0.025)\n","name":"stdout"}]},{"metadata":{"id":"2c16EMYEVa13"},"cell_type":"markdown","source":"## Vectorize texts"},{"metadata":{"id":"zy_YxJk16ROj"},"cell_type":"markdown","source":"Can be later integrated into the model as initial embedding layer."},{"metadata":{"id":"3aYkVKWQjFZq"},"cell_type":"markdown","source":"https://intellipaat.com/community/12732/using-pre-trained-word2vec-with-lstm-for-word-generation"},{"metadata":{"executionInfo":{"elapsed":35340,"status":"ok","timestamp":1607357626949,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"qh5yNBH1ykSA","outputId":"6e544682-e6ca-49ff-e3be-b6283f676995","trusted":true},"cell_type":"code","source":"# length of each sentences\nK = words.text.apply(len)\n\n# plot ratio\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,12)\npd.Series(K).plot(kind = \"hist\", bins = 35);\n\n# maximum sentence length\nKmax = K.max()\nprint(\"Maximal sentence length:\", Kmax)","execution_count":7,"outputs":[{"output_type":"stream","text":"Maximal sentence length: 2832\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x864 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"executionInfo":{"elapsed":35790,"status":"ok","timestamp":1607357627416,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"uTBcTyVs0YTm","outputId":"5271d6e4-b0c6-4feb-dd43-6efae9afaa1b","trusted":true},"cell_type":"code","source":"# drop too long sentences\nd1 = words.shape[0]\ninput_size = 1200\nwords = words[K <= input_size]\\\n  .reset_index(drop = True)\nd2 = words.shape[0]\n\"Dropped %d of %d samples (%5.3f %%).\" % (d1 - d2, d1, (1 - d2/d1) * 100)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'Dropped 305 of 196292 samples (0.155 %).'"},"metadata":{}}]},{"metadata":{"executionInfo":{"elapsed":36134,"status":"ok","timestamp":1607357627777,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"p4NdIegBabgx","outputId":"4813dd0d-67c0-403a-c297-8f0fcfeb591f","trusted":true},"cell_type":"code","source":"# length of each sentences\nK = words.text.apply(len)\n\n# plot ratio\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,12)\npd.Series(K).plot(kind = \"hist\", bins = 60);\n\n# maximum sentence length\nKmax = K.max()\nprint(\"Maximal sentence length:\", Kmax)","execution_count":9,"outputs":[{"output_type":"stream","text":"Maximal sentence length: 1200\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x864 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"executionInfo":{"elapsed":60181,"status":"ok","timestamp":1607357651838,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"maVuoliJODK0","outputId":"63127b09-79dc-41db-c4ad-9558134ad89c","trusted":true},"cell_type":"code","source":"# dimensions\nN    = words.shape[0]\nK    = words.text.apply(len).to_numpy()\nKmax = K.max()\n\n# train data\ntrain_y = words.label.to_numpy()\ntrain_x = np.zeros([N, Kmax], dtype=np.int32)\nfor i,row in words.iterrows():\n  for j,word in enumerate(row.text):\n    # map words\n    train_x[i,j] = word2vec.wv.vocab[word].index\n\n# remove empty lines\nnonempty_lines = K > 0\ntrain_x = train_x[nonempty_lines,:]\ntrain_y = train_y[nonempty_lines]\nK = K[nonempty_lines]\n\n# result\nprint(\"Train data |%d x %d|\" % (train_x.shape))\nprint(\"Labels |%d x 1|\" % (train_y.shape))\n\n# drop original dataframe (save RAM)\ndel words","execution_count":10,"outputs":[{"output_type":"stream","text":"Train data |195950 x 1200|\nLabels |195950 x 1|\n","name":"stdout"}]},{"metadata":{"id":"2Uj80Ygog73U"},"cell_type":"markdown","source":"## Model definition"},{"metadata":{"id":"XDbCVQHai6Mj"},"cell_type":"markdown","source":"https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n\nhttps://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n\nhttps://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/402_RNN_classifier.py"},{"metadata":{"id":"6CR5c2uig-Tb"},"cell_type":"markdown","source":"### Generator"},{"metadata":{"executionInfo":{"elapsed":60173,"status":"ok","timestamp":1607357651840,"user":{"displayName":"Martin Beneš","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm2LbV6RJT4SHSv_UayaRX091SFYYHPcZtMZOnAw=s64","userId":"17903291412993378699"},"user_tz":-60},"id":"lFyyysharJNo","trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n  \"\"\"Generator code.\"\"\"\n  def __init__(self, output_size, input_size = 1, hidden_state = 5, num_layers = 1):\n    \"\"\"Generator constructor.\n    \n    Args:\n      ngpu (int): Number of GPUs.\n      kfeat (int, optional): Number of features, by default 1.\n    \"\"\"\n    super(Generator, self).__init__()\n    \n    # LSTM layer\n    self.lstm = nn.LSTM(input_size,   # input size\n                        hidden_state, # hidden size\n                        num_layers)   # number of layers\n\n    # linear final layer\n    self.linear = nn.Linear(hidden_state, output_size)\n\n  def forward(self, input):\n    h1, (hn, cn) = self.lstm(input)\n    o  = self.linear(h1)\n    return o\n","execution_count":11,"outputs":[]},{"metadata":{"id":"r-JbT7yy6h3a","outputId":"0f87b0e6-66d5-48dc-90f1-d12a63063eba","trusted":true},"cell_type":"code","source":"hidden_size = 60\nvocab_size = len(word2vec.wv.vocab)\nbatch_size = 100\nnum_layers = 2\nnum_epochs = 1\nlearning_rate = 0.02\n\n# connect to device\n#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice = torch.device(\"cpu\")\n# instantiate \nmodel = Generator(vocab_size, 1, #input_size\n                  hidden_size, num_layers)#\\.to(device)\nprint(model)\n\n# loss, optimizer\n#loss_fn = nn.CrossEntropyLoss()\n#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# inputs\ntrain_x_torch = torch.from_numpy(train_x.astype(np.float32))\ntrain_y_torch = torch.from_numpy(train_y.astype(np.float32))\n\n# drop original\ndel train_x\ndel train_y\n\nprint(\"Input matrix:\", train_x_torch.shape)\nprint(\"Input targets:\", train_y_torch.shape)\n\nbatch_1percent = np.ceil(train_x_torch.shape[0] / batch_size) / 100\n\nwith torch.no_grad():\n    for epoch in range(num_epochs):\n        # Set initial hidden and cell states\n        #states = (torch.zeros(input_size, hidden_size).to(device),\n        #          torch.zeros(hidden_size, hidden_size).to(device))\n    \n        for it,i in enumerate(range(0, train_x_torch.shape[0], batch_size)):\n            # get input\n            #input_vector = train_x_torch[i,:K[i]]#.view(1, 1, input_size)\n            #input_target = train_y_torch[i]#.view(1, 1)#.reshape((-1,input_size))\n            #train_x_input = train_x[i,:K[i]].astype(np.float32)\n            #train_y_input = train_y[i].astype(np.float32)\n            #print(\"Input vector:\", train_x_input.shape)\n            #print(\"Input target:\", train_y_input.shape)\n            batch_end = min(i + batch_size, train_x_torch.shape[0])\n            batch_size_ = batch_end - i\n            input_vector = train_x_torch[i:batch_end,:K[i]]\\\n                .view((batch_size_,K[i],1))#\\.to(device)\n            input_target = train_y_torch[i:batch_end]\\\n                .view((batch_size_))#\\.to(device)\n            #print(\"Input vector:\", input_vector.shape)\n            #print(\"Input target:\", input_target.shape)\n            #break\n            # truncated backpropagation\n            #states = [state.detach() for state in states]\n            #print(input_vector.shape)\n            output = model(input_vector)\n            #print(\"Output:\", output.shape)\n\n            # classical\n            #loss = loss_fn(output, input_target) # \n            #model.zero_grad()\n            #loss.backward()\n            # gradient clipping\n            #torch.nn.utils.clip_grad_norm(model.parameters(), .5)\n            #optimizer.step()\n\n            #del input_vector\n            #del input_target\n            \n            torch.cuda.empty_cache()\n    \n            #if it % batch_1percent == 0:\n            if it % 10 == 0:\n                print(\"\\r%5.3f %%%s\" % (i / train_x_torch.shape[0] * 100, \" \"*10), end = \"\")\n            #print(i)\n            # add discriminator\n        else:\n            loss = 42.\n            print ('Epoch [{}/{}], Loss: {:.4f}'\n                .format(epoch+1, num_epochs, loss.item()))\n      \n    #for i in range(0, input_tensor.size(1) - timesteps, timesteps):\n    #    # Get mini-batch inputs and targets\n    #    inputs = input_tensor[:, i:i+timesteps].to(device)\n    #    targets = input_tensor[:, (i+1):(i+1)+timesteps].to(device)\n        \n    #    states = detach(states)\n    #    outputs,_ = model(inputs, states)\n    #    loss = loss_fn(outputs, targets.reshape(-1))\n\n    #    model.zero_grad()\n    #    loss.backward()\n        # Perform Gradient Clipping\n    #    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n    #    optimizer.step()\n    \n    #else:\n    #    print ('Epoch [{}/{}], Loss: {:.4f}'\n    #       .format(epoch+1, num_epochs, loss.item()))","execution_count":null,"outputs":[{"output_type":"stream","text":"Generator(\n  (lstm): LSTM(1, 60, num_layers=2)\n  (linear): Linear(in_features=60, out_features=307967, bias=True)\n)\nInput matrix: torch.Size([195950, 1200])\nInput targets: torch.Size([195950])\n","name":"stdout"}]},{"metadata":{"id":"2JF_DUJBcXCW","trusted":true},"cell_type":"code","source":"#def weights_init(m):\n#  \"\"\"Custom weights initialization called on netG and netD.\"\"\"\n#  classname = m.__class__.__name__\n#  if classname.find('Conv') != -1:\n#    nn.init.normal_(m.weight.data, 0.0, 0.02)\n#  elif classname.find('BatchNorm') != -1:\n#    nn.init.normal_(m.weight.data, 1.0, 0.02)\n#    nn.init.constant_(m.bias.data, 0)\n\n#class Generator(nn.Module):\n#  \"\"\"Generator code.\"\"\"\n#  def __init__(self, ngpu):\n#    super(Generator, self).__init__()\n    \n    # Number of GPUs available. Use 0 for CPU mode.\n#    self.ngpu = ngpu\n    # Batch size during training\n#    self.batch_size = 128\n    # Spatial size of training images. All images will be resized to this\n    #   size using a transformer.\n#    self.image_size = 64\n    # Number of channels in the training images. For color images this is 3\n#    self.nc = 3\n    # Size of z latent vector (i.e. size of generator input)\n#    self.nz = 100\n    # Size of feature maps in generator\n#    self.ngf = 64\n    # Size of feature maps in discriminator\n#    self.ndf = 64\n    # Number of training epochs\n#    self.num_epochs = 5\n    # Beta1 hyperparam for Adam optimizers\n#    self.beta1 = 0.5\n\n#    self.main = nn.Sequential(\n      # input is Z, going into a convolution\n#      nn.ConvTranspose2d( self.nz, self.ngf * 8, 4, 1, 0, bias=False),\n#      nn.BatchNorm2d(self.ngf * 8),\n#      nn.ReLU(True),\n      # state size. (ngf*8) x 4 x 4\n#      nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ngf * 4),\n#      nn.ReLU(True),\n      # state size. (ngf*4) x 8 x 8\n#      nn.ConvTranspose2d( self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ngf * 2),\n#      nn.ReLU(True),\n      # state size. (ngf*2) x 16 x 16\n#      nn.ConvTranspose2d( self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ngf),\n#      nn.ReLU(True),\n      # state size. (ngf) x 32 x 32\n#      nn.ConvTranspose2d( self.ngf, self.nc, 4, 2, 1, bias=False),\n#      nn.Tanh()\n      # state size. (nc) x 64 x 64\n#    )\n\n#  def forward(self, input):\n#    return self.main(input)\n\n# Create the generator\n#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n#print(\"Device used:\", device)\n#netG = Generator(ngpu).to(device)\n\n# Handle multi-gpu if desired\n#if (device.type == 'cuda') and (ngpu > 1):\n#    netG = nn.DataParallel(netG, list(range(ngpu)))\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\n#netG.apply(weights_init)\n\n# Print the model\n#print(netG)","execution_count":null,"outputs":[]},{"metadata":{"id":"mkG9I2pKhA5b"},"cell_type":"markdown","source":"### Discriminator"},{"metadata":{"id":"pts3SkEaf6H7","trusted":true},"cell_type":"code","source":"#class Discriminator(nn.Module):\n#  def __init__(self, ngpu):\n#    super(Discriminator, self).__init__()\n    # Number of GPUs available. Use 0 for CPU mode.\n#    self.ngpu = ngpu\n    # Batch size during training\n#    self.batch_size = 128\n    # Spatial size of training images. All images will be resized to this\n    #   size using a transformer.\n#    self.image_size = 64\n    # Number of channels in the training images. For color images this is 3\n#    self.nc = 3\n    # Size of z latent vector (i.e. size of generator input)\n#   self.nz = 100\n    # Size of feature maps in generator\n#    self.ngf = 64\n    # Size of feature maps in discriminator\n#    self.ndf = 64\n    # Number of training epochs\n#    self.num_epochs = 5\n    # Beta1 hyperparam for Adam optimizers\n#    self.beta1 = 0.5\n\n#    self.main = nn.Sequential(\n      # input is (nc) x 64 x 64\n#      nn.Conv2d(self.nc, self.ndf, 4, 2, 1, bias=False),\n#      nn.LeakyReLU(0.2, inplace=True),\n      # state size. (ndf) x 32 x 32\n#      nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ndf * 2),\n#      nn.LeakyReLU(0.2, inplace=True),\n      # state size. (ndf*2) x 16 x 16\n#      nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ndf * 4),\n#      nn.LeakyReLU(0.2, inplace=True),\n      # state size. (ndf*4) x 8 x 8\n#      nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False),\n#      nn.BatchNorm2d(self.ndf * 8),\n#      nn.LeakyReLU(0.2, inplace=True),\n      # state size. (ndf*8) x 4 x 4\n#      nn.Conv2d(self.ndf * 8, 1, 4, 1, 0, bias=False),\n#      nn.Sigmoid()\n#    )\n\n##  def forward(self, input):\n#    return self.main(input)\n\n# Create the Discriminator\n#netD = Discriminator(ngpu).to(device)\n\n# Handle multi-gpu if desired\n#if (device.type == 'cuda') and (ngpu > 1):\n#    netD = nn.DataParallel(netD, list(range(ngpu)))\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\n#netD.apply(weights_init)\n\n# Print the model\n#print(netD)","execution_count":null,"outputs":[]},{"metadata":{"id":"tIPDRbXLhCnL"},"cell_type":"markdown","source":"### Optimizer\n"},{"metadata":{"id":"VPepDlZ5gmEM","trusted":true},"cell_type":"code","source":"# Initialize BCELoss function\n#criterion = nn.BCELoss()\n\n# Create batch of latent vectors that we will use to visualize\n#  the progression of the generator\n#nz = 100\n#fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n\n# Establish convention for real and fake labels during training\n#real_label = 1.\n#fake_label = 0.\n\n# Setup Adam optimizers for both G and D\n#lr = 0.0002 # Learning rate for optimizers\n#optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n#optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"id":"f5agAO7NhFir"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"ZVe6diUbhLuC","trusted":true},"cell_type":"code","source":"# Training Loop\n#num_epochs = 10\n\n# Lists to keep track of progress\n#img_list = []\n#G_losses = []\n#D_losses = []\n#iters = 0\n\n#print(\"Starting Training Loop...\")\n# For each epoch\n#for epoch in range(1,num_epochs+1):\n    # For each batch in the dataloader\n#    for i, data in enumerate(train_x, 1):\n\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        ## Train with all-real batch\n        #netD.zero_grad()\n        # Format batch\n        #real_cpu = data[0].to(device)\n        #b_size = real_cpu.size(0)\n        #label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n        # Forward pass real batch through D\n        #output = netD(real_cpu).view(-1)\n        # Calculate loss on all-real batch\n        #errD_real = criterion(output, label)\n        # Calculate gradients for D in backward pass\n        #errD_real.backward()\n        #D_x = output.mean().item()\n\n        ## Train with all-fake batch\n        # Generate batch of latent vectors\n        #noise = torch.randn(b_size, nz, 1, 1, device=device)\n        # Generate fake image batch with G\n        #fake = netG(noise)\n        #label.fill_(fake_label)\n        # Classify all fake batch with D\n        #output = netD(fake.detach()).view(-1)\n        # Calculate D's loss on the all-fake batch\n        #errD_fake = criterion(output, label)\n        # Calculate the gradients for this batch\n        #errD_fake.backward()\n        #D_G_z1 = output.mean().item()\n        # Add the gradients from the all-real and all-fake batches\n        #errD = errD_real + errD_fake\n        # Update D\n        #optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        #netG.zero_grad()\n        #label.fill_(real_label)  # fake labels are real for generator cost\n        # Since we just updated D, perform another forward pass of all-fake batch through D\n        #output = netD(fake).view(-1)\n        # Calculate G's loss based on this output\n        #errG = criterion(output, label)\n        # Calculate gradients for G\n        #errG.backward()\n        #D_G_z2 = output.mean().item()\n        # Update G\n        #optimizerG.step()\n\n        # Output training stats\n        #if i % 20000 == 0 or i == train_x.shape[0]:\n        #    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n        #          % (epoch, num_epochs, i, train_x.shape[0],\n        #             0, 0, 0, 0, 0))\n                     #errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        # Save Losses for plotting later\n        #G_losses.append(errG.item())\n        #D_losses.append(errD.item())\n\n        # Check how the generator is doing by saving G's output on fixed_noise\n        #if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n        #    with torch.no_grad():\n        #        fake = netG(fixed_noise).detach().cpu()\n        #    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        #iters += 1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}